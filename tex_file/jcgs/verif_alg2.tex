%\subsection{Correctness of the proposed algorithm }
%\label{sec:verify2}
\begin{proposition}
  The sampler described in Algorithm~\ref{alg:MH_improved} has the posterior
  distribution $p(\theta,S(t)|X)$ as its stationary distribution.
\end{proposition}
\begin{proof}
  Suppose that at the start of the algorithm, we have a pair $(\theta,S(t))$ from
  the posterior distribution $p(\theta,S(t)|X)$. Introducing $\theta^*$
  from $q(\theta^*|\theta)$ results in a triplet whose marginal over the first
  two variables is still $p(\theta,S(t)|X)$.

  Sampling $U$ from a Poisson process with rate $\Omega(\theta) +
  \Omega(\theta^*) - A_{S(t)}(\theta)$, results in a random grid $W = T \bigcup U$
  that is distributed according to a rate $\Omega(\theta) + \Omega(\theta^*)$
  Poisson process (Proposition 2 in~\cite{RaoTeh13}). Discarding all state 
  information results in a triplet $(W,\theta,\theta^*)$ with probability
  proportional to $p(\theta)q(\theta^*|\theta)p(W|\theta,\theta^*)
  p(X|W,\theta,\theta^*)$.

Next we propose swapping $\theta$ and $\theta^*$, since this
is a deterministic proposal, the MH-acceptance probability is given by
$$\alpha = 1 \wedge \frac{p(\theta^*)q(\theta|\theta^*)p(W|\theta^*,\theta)
p(X|W,\theta^*,\theta)}{p(\theta)q(\theta^*|\theta)p(W|\theta,\theta^*)
p(X|W,\theta,\theta^*)}$$
The term $p(W|\theta,\theta^*)$ is just a Poisson process with rate $\Omega(\theta)+
\Omega(\theta^*)$, so that $p(W|\theta,\theta^*) = p(W|\theta,\theta^*)$. The
two terms $p(X|W,\theta,\theta^*)$ and $p(X|W,\theta^*,\theta)$ are obtained
at the end of a forward pass over $W$ using discrete-time transition matrices
$B(\theta,\theta^*) = \left(I + \frac{A(\theta)}{\Omega(\theta)+\Omega(\theta^*)}\right)$ 
and $B(\theta^*,\theta) = \left(I + \frac{A(\theta^*)}{\Omega(\theta)+\Omega(\theta^*)}\right)$. 

Calling the parameters 
after the accept step $(\tilde{\theta}, \tilde{\theta}^*)$, we have that
$(\tilde{\theta}, \tilde{\theta}^*,W)$ has the same distribution as
$(\theta, \theta^*,W)$.
Finally, following Lemma 1 in~\cite{RaoTeh13}, using the matrix 
$B(\tilde{\theta},\tilde{\theta}^*)$ to make a backward pass through $W$,
and discarding the self-transitions results in a trajectory $(\tilde{S}(t)$
distributed according to $A(\tilde{\theta})$. Discarding the auxiliary parameter
$\tilde{\theta}^*$ results is a pair $(\tilde{\theta},\tilde{S}(t))$ from
the posterior.
% \begin{align*}
%  p(y, W, S, T, \theta, \theta^*) &= p(\theta) q(\theta^* | \theta) P(S,T| \theta, \theta^*) P(W| S, T, \theta, \theta^*)P(y | S, T, \theta, \theta^*)\\
%  &=p(\theta) q(\theta^* | \theta) P(S,T| \theta) P(W| S, T, \theta, \theta^*)P(y | S, T).
% \end{align*}
% The marginal distribution of $(y, S, T, \theta, \theta^*)$ and $(y, S, T, \theta)$ as follows.\\
% \begin{align*}
%  p(y, S, T, \theta, \theta^*) &= p(\theta) q(\theta^* | \theta) P(S,T| \theta, \theta^*)P(y | S, T, \theta, \theta^*)\\
%  &=P(y, S, T, \theta) q(\theta^* | \theta).
% \end{align*}
% \begin{align*}
%  p(y, S, T, \theta) &= p(\theta)P(S,T| \theta)P(y | S, T, \theta).
% \end{align*}
% So the conditional distribution over $\theta^*$ given $(y, S, T, \theta)$ is $q(\theta^* | \theta)$. And the conditional distribution over W given $(y, S, T, \theta, \theta^*)$  is $P(W | S, T, \theta, \theta^*)$, which is actually the distribution of Non Homogeneous Poisson Process with piecewise constant rate $h(\theta) + h(\theta^*) - A_{S(t)}(\theta)$.\\
% Thus the Step 1 + Step 2 is actually equivalent to sampling from the conditional distribution $P(\theta^* , W| S, T, \theta, y)$.\\
% The Step 3 + Step 4 satisfy the detailed balance condition. The reason is as follows.
% \begin{align*}
% &P((W, S, T, (\theta, \theta^*)) \rightarrow (W, S^*, T^*, (\theta^*, \theta))) P(S,T, (\theta, \theta^*) | W, y)\\
% &= (1 \wedge \frac{P((\theta^*,\theta) | W, y)}{P((\theta,\theta^*) | W, y)})P(S^*, T^* | W, (\theta^*, \theta), y)P(S, T | W, (\theta, \theta^*), y)P((\theta, \theta^*) | W, y)\\
% &= P((W, S^*, T^*, (\theta^*, \theta)) \rightarrow (W, S, T, (\theta, \theta^*))) P(S^*,T^*, (\theta^*, \theta) | W, y)
% \end{align*} 
% Therefore the stationary distribution of this MCMC sampler is $P(W, S, T, (\theta, \theta^*) | y)$. Thus the stationary distribution of $(S, T, \theta)$ is the corresponding marginal distribution $P(S, T, \theta | y)$.  
\end{proof}

\subsection{Comments}

The uniformization scheme of~\cite{RaoTeh13} works for any underlying Poisson
process whose rate $\Omega$ is greater than $\max_i A_i$. The strict inequality
ensures that the conditional probability of sampling one or more thinned events 
$U$ is positive for every trajectory $S(t)$ (recall 
$U \sim \text{PoissonProc}(\Omega-A_{S(t)})$). Empirical results from~\cite{RaoTeh13}
suggest setting $\Omega = 2 \max_i A_i$.

Implicit in our new scheme is a uniformizing Poisson process with rate
$\Omega(\theta,\theta') = \Omega(\theta) + \Omega(\theta')$. For our 
scheme to be valid, $\Omega(\theta,\theta')$ must be greater than both
$\max_i A_i(\theta)$ and $\max_i A_i(\theta')$. The smallest and simplest such
choice is $\Omega(\theta,\theta') = \max A_i(\theta) + \max A_i(\theta')$.
For a fixed $\theta$, this reduces to $\Omega = 2\max A_i$, providing
an intuitive motivation for the approach in~\cite{RaoTeh13}.
Larger alternatives include 
$\Omega(\theta,\theta') = \kappa(\max A_i(\theta) + \max A_i(\theta'))$
for $\kappa > 1$.  These result in more thinned events, and therefore more 
computation, with the benefit of faster MCMC mixing. We study the effect of 
$\kappa$ in our experiments.

It is also possible to have non-additive settings for $\Omega(\theta,\theta')$.
A simple option is to set it equal to 
$\kappa \max( \max_i A_i(\theta), \max A_i(\theta')$ for some choice of $\kappa
> 1$. We investigate this option as well.
