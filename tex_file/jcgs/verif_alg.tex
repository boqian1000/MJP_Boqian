%\subsection{Correctness of the proposed algorithm }
%\label{sec:verify2}
\begin{proposition}
  The sampler described in Algorithm~\ref{alg:MH_improved} has the posterior distribution $P(\theta,S(t)|X)$ as its stationary distribution.
\end{proposition}
\begin{proof}
  Consider a realization $(s_0,S,T,\theta)$ from the posterior distribution $P(\theta, s_0, S, T|X)$. An iteration of the algorithm first simulates $\vartheta$ from $q(\vartheta|\theta)$. By construction, the marginal distribution over all but the last variable in the set $(\theta, s_0, S, T, \vartheta)$ is still the posterior.

  The algorithm next simulates $U$ from a Poisson process with rate $\Omega(\theta,\vartheta) - A_{S(t)}(\theta)$. Write $W = T \cup U$.
  The random grid $W$ consists of the actual and thinned candidate transition times, and is distributed according to a rate-$\Omega(\theta, \vartheta)$ Poisson process (Proposition 2 in~\cite{RaoTeh13}). 
  Thus, the triplet $(W,\theta,\vartheta)$ has probability proportional to $P(\theta)q(\vartheta|\theta)\text{PoissProc}(W|\Omega(\theta,\vartheta)) P(X|W,\theta,\vartheta)$.
  Next, the algorithm proposes swapping $\theta$ and $\vartheta$ 
  (a deterministic proposal), and accepts with MH-acceptance probability 
  $$\texttt{acc} = 
  1 \wedge \frac{P(\vartheta)q(\theta|\vartheta)
P(X|W,\vartheta,\theta)}{P(\theta)q(\vartheta|\theta)
P(X|W,\theta,\vartheta)} =
1 \wedge \frac{P(\vartheta)q(\theta|\vartheta)\text{PoissProc}(W|\Omega(\vartheta,\theta)) P(X|W,\vartheta,\theta)}{P(\theta)q(\vartheta|\theta)\text{PoissProc}(W|\Omega(\theta,\vartheta))
P(X|W,\theta,\vartheta)},$$
where we exploit the symmetry of $\Omega(\cdot,\cdot)$.
%in its two arguments.
%$P(W|\theta,\vartheta)$ is just a Poisson process with rate $\Omega(\theta)+ \Omega(\vartheta)$, so that $P(W|\theta,\vartheta) = P(W|\theta,\vartheta)$, which can be ignored when calculating $\texttt{acc}$. 
%$P(X|W,\theta,\vartheta)$ and $P(X|W,\vartheta,\theta)$ are obtained
%after a forward pass over $W$ using discrete-time transition matrices
%$B(\theta,\vartheta) = \left(I + \frac{A(\theta)}{\Omega(\theta)+\Omega(\vartheta)}\right)$ 
%and $B(\vartheta,\theta) = \left(I + \frac{A(\vartheta)}{\Omega(\theta)+\Omega(\vartheta)}\right)$. 
Write the new parameters as $(\theta', \vartheta')$. 

The Markov kernel has stationary distribution over $(\theta',\vartheta')$ proportional to
$P(\theta')q(\vartheta'|\theta)$ $\text{PoissProc}(W|\Omega(\theta',\vartheta'))
P(X|W,\theta',\vartheta')$, and the triplet $(\theta', \vartheta',W)$ has the same distribution as $(\theta, \vartheta,W)$.
The algorithm uses $B(\theta',\vartheta')$ to make a backward pass through $W$, simulating state values on $W$ from the conditional of a Markov chain with transition matrix $B(\theta',\vartheta')$ given observations $X$. 
Dropping the self-transition times results in $(\theta', s'_0, S', T', \vartheta')$. 
From uniformization (see also Lemma 1 in~\cite{RaoTeh13}), the trajectory $(s'_0, S', T')$ is distributed according to the conditional of a rate-$A(\theta')$ MJP given observations $X$.
Finally, dropping $\vartheta'$ 
%effectively marginalizing this parameter.  As we saw at the start of the proof, this  
results in $(\theta',s'_0,S',T')$ from the posterior given $X$.
% \begin{align*}
%  p(y, W, S, T, \theta, \theta^*) &= p(\theta) q(\theta^* | \theta) P(S,T| \theta, \theta^*) P(W| S, T, \theta, \theta^*)P(y | S, T, \theta, \theta^*)\\
%  &=p(\theta) q(\theta^* | \theta) P(S,T| \theta) P(W| S, T, \theta, \theta^*)P(y | S, T).
% \end{align*}
% The marginal distribution of $(y, S, T, \theta, \theta^*)$ and $(y, S, T, \theta)$ as follows.\\
% \begin{align*}
%  p(y, S, T, \theta, \theta^*) &= p(\theta) q(\theta^* | \theta) P(S,T| \theta, \theta^*)P(y | S, T, \theta, \theta^*)\\
%  &=P(y, S, T, \theta) q(\theta^* | \theta).
% \end{align*}
% \begin{align*}
%  p(y, S, T, \theta) &= p(\theta)P(S,T| \theta)P(y | S, T, \theta).
% \end{align*}
% So the conditional distribution over $\theta^*$ given $(y, S, T, \theta)$ is $q(\theta^* | \theta)$. And the conditional distribution over W given $(y, S, T, \theta, \theta^*)$  is $P(W | S, T, \theta, \theta^*)$, which is actually the distribution of Non Homogeneous Poisson Process with piecewise constant rate $h(\theta) + h(\theta^*) - A_{S(t)}(\theta)$.\\
% Thus the Step 1 + Step 2 is actually equivalent to sampling from the conditional distribution $P(\theta^* , W| S, T, \theta, y)$.\\
% The Step 3 + Step 4 satisfy the detailed balance condition. The reason is as follows.
% \begin{align*}
% &P((W, S, T, (\theta, \theta^*)) \rightarrow (W, S^*, T^*, (\theta^*, \theta))) P(S,T, (\theta, \theta^*) | W, y)\\
% &= (1 \wedge \frac{P((\theta^*,\theta) | W, y)}{P((\theta,\theta^*) | W, y)})P(S^*, T^* | W, (\theta^*, \theta), y)P(S, T | W, (\theta, \theta^*), y)P((\theta, \theta^*) | W, y)\\
% &= P((W, S^*, T^*, (\theta^*, \theta)) \rightarrow (W, S, T, (\theta, \theta^*))) P(S^*,T^*, (\theta^*, \theta) | W, y)
% \end{align*} 
% Therefore the stationary distribution of this MCMC sampler is $P(W, S, T, (\theta, \theta^*) | y)$. Thus the stationary distribution of $(S, T, \theta)$ is the corresponding marginal distribution $P(S, T, \theta | y)$.  
%\qed
\end{proof}

\section{Related work}\label{sec:comments}
 %the set of transition times is unbounded, with individual elements
 %unconstrained over the observation interval $[0,\cT]$.
 %Naively calculating this marginal probability for the continuous-time
 %case is not straightforward, as there is no finite set of candidate
 %times to make a pass over. 

Our paper modifies the algorithm from~\citet{RaoTeh13} to include parameter inference.
That algorithm requires a uniformization rate $\Omega(\theta) > \max_s A_s(\theta)$, and empirical results from that paper suggest $\Omega(\theta) = 2\max_s A_s(\theta)$.
The uniformization rate $\Omega(\theta,\vartheta)$ in our algorithm includes a proposed new parameter $\vartheta$, must be symmetric in both arguments and must be greater than both $\max_s A_s(\theta)$ and $\max_s A_s(\vartheta)$. 
A natural and simple setting is $\Omega(\theta,\vartheta) = \max_s A_s(\theta) + \max_s A_s(\vartheta)$. 
When $\theta$ is known, our algorithm has $\vartheta$ equal to $\theta$ (i.e.\ the proposed $\vartheta$ equals $\theta$), and our uniformization rate reduces to $2\max A_i$. 
This provides a principled motivation for the particular choice of $\Omega$ in~\citet{RaoTeh13}.

Of course, we can consider other choices for the uniformization rate, such as $\Omega(\theta,\vartheta) = \kappa(\max A_i(\theta) + \max A_i(\vartheta))$ for $\kappa > 1$.  These result in more thinned events, and so more computation, with the benefit of faster MCMC mixing. We study the effect of 
$\kappa$ in our experiments, but find the smallest setting of $\kappa=1$ performs best.
It is also possible to have non-additive settings for $\Omega(\theta,\vartheta)$, for example, $\Omega(\theta,\vartheta) = \kappa \max( \max_i A_i(\theta), \max A_i(\vartheta))$ for some choice of $\kappa > 1$. We investigate this as well.

A key idea in our paper, as well as~\cite{RaoTeh13}, is to impute the random grid of candidate transition times $W$ every MCMC iteration. 
Conditioned on $W$, the MJP trajectory follows a Markov chain with transition matrix $B$. 
By running the FFBS algorithm over $W$, we can marginalize out the states associated with $W$, and calculate the marginal $P(X|W,\theta)$. 
Another approach to parameter inference that integrates out state values follows~\citet{FearnSher2006}. 
 This algorithm makes a sequential forward pass through all {\em observations} $X$ (rather than $W$). 
 Unlike with $W$, one cannot a priori bound the number of transitions between two successive observations, so that~\citet{FearnSher2006} have to use a matrix exponential of $A$ (rather than $B$) to calculate transition probabilities.
 The resulting algorithm is cubic, rather than quadratic in the number of states, and the number of expensive matrix exponentiations needed scales with the number of observations, rather than the number of transitions.
 Further, matrix exponentiation results in a dense matrix, so that~\cite{FearnSher2006} cannot exploit sparsity in the transition matrix.
 In our framework, $B=I+\frac{1}{\Omega}A$ inherits sparsity present in $A$.

 A second approach to marginalizing out state information is particle MCMC~\citep{Andrieu10}. 
 This algorithm, describe in section~\ref{sec:pmcmc} in the supplementary material, uses particle filtering to get an unbiased estimate of $P(X|\theta)$. 
 Plugging this estimate into the MH acceptance probability results in an MCMC sampler that targets the correct posterior, however the resulting scheme does not exploit the Markovian structure of the MJP the way FFBS can. 
 In particular, observations that are informative of the MJP state can result in marginal probability estimates that have large variance, resulting in slow mixing. 
 By contrast, given $W$, FFBS can compute the marginal probability $P(X|W,\theta)$ {\em exactly}. 

The basic idea of marginalizing out information to accelerate MCMC convergence rates is formalized by the idea of the Bayesian fraction of missing information~\citep{liu1994fraction}. 
In this context, papers such as~\citet{papaspiliopoulos2007general,yu2011center} have studied MCMC algorithms for hierarchical (or latent variable) models. 
Uniformization forms such a hierarchical representation for MJPs: first sample $\theta$, then sample the latent variable $W$, and use this to sample MJP state values. 
The \naive\ algorithm~\ref{alg:MH_naive} is a direct application of ideas presented in those papers.
These frameworks are broad enough to accommodate our symmetrized MH algorithm~\ref{alg:MH_improved} as well. 
This recasts our contribution as a rewriting of uniformization that now includes the auxiliary parameter $\vartheta$. Our swap operator then forms a particular Markov kernel that exploits this reparametrization. 
Two interesting directions are to see how such symmetrization ideas apply to other problems considered in those works, and how ideas from those works can shed more light on, and improve our algorithm.

 %
 %
Our approach of first simulating $\vartheta$, and then simulating $W$ from a Poisson process whose rate is symmetric in $\theta$ and $\vartheta$ is related to a framework outlined in~\citet{Neal04Drag}. In that work, to simulate from an `energy' model of two variables $P(x,y) \propto \exp(-E(x,y))$, the author proposes a new parameter $x^*$, and then updates $y$ via intermediate transitions to be symmetric in $x$ and $x^*$. Our approach exploits the specific structure of the Poisson and Markov jump processes to do this directly, avoiding the need for any tempered transitions. 

Our algorithm is also related to work on MCMC for doubly-intractable distributions.  Algorithms like~\cite{Moller2006,murray2006,Andrieu09} all attempt to evaluate an intractable likelihood under a proposed parameter $\vartheta$ by introducing auxiliary variables, typically sampled independently under the proposed parameters. 
For MJPs, this would involve proposing $\vartheta$, generating a new grid $W^*$, and then using $P(X|W,\theta)$ and $P(X|W^*,\vartheta)$ in the MH acceptance step. 
This can complicate computations (with two sets of grids), and introduce additional variance thereby reducing acceptance rates. %if the new parameter $\vartheta$ is incompatible with the old grid $U$ or vice versa. 
While~\cite{murray2006} suggest annealing schemes to try to address this issue, we exploit the structure of the Poisson process and provide a cleaner solution: generate a single set of auxiliary variables that depends symmetrically on both the new and old parameters. 
%It is interesting to see whether a similar idea can be used in other applications as well.
