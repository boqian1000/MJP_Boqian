
\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes widely used in fields like computational chemistry~\citep{gillespie97}, molecular genetics~\citep{FearnSher2006}, mathematical finance~\citep{Elliott06}, queuing theory~\citep{Breuer2003}, artificial intelligence~\citep{XuShe10} and social-network analysis~\citep{pan2016markov}. 
MJPs have been used as realistic, mechanistic and interpretable models of a wide variety of phenomena, among others, the references above have used them to model temporal evolution of the state of a chemical reaction or queuing network, segmentation of a strand of DNA, and user activity on social media.
Their continuous-time dynamics however raise computational challenges when, given noisy measurements, one wants to make inferences 
over the latent MJP trajectory as well as any process parameters. 
In contrast to {discrete-time} hidden Markov models, one cannot 
{\em a priori} bound the number of trajectory state transitions, and the transition times themselves are continuous-valued. 
The state-of-the-art approach is an auxiliary variable Gibbs sampler from~\cite{RaoTeh13}, we will refer to this as the {\algname} algorithm. 
This Markov chain Monte Carlo (MCMC) algorithm was designed to simulate paths when the MJP parameters are known. 
Parameter inference is typically carried out by incorporating it into a Gibbs sampler that also conditionally simulates parameters given the currently sampled trajectory. 

In many situations, the MJP trajectory and parameters exhibit strong coupling, so that alternately sampling path given parameters, and parameters given path can result in poor mixing.  
To address this, we propose an efficient Metropolis-Hastings (MH) sampler (algorithm~\ref{alg:MH_improved}). 
%additionally, we tie up some of the loose ends in the Rao-Teh algorithm.
In our experiments, we demonstrate superior performance over Gibbs sampling, a more \naive\ MH sampler (algorithm~\ref{alg:MH_naive}), as well as particle Markov chain Monte Carlo~\citep{Andrieu10}. 
We also prove that under relatively mild conditions, our sampler inherits geometric ergodicity from an `ideal' sampler that is computationally much more expensive.

\section{Markov jump processes (MJPs)} 
\label{sec:mjp}
A Markov jump process~\citep{Cinlar1975} is a right-continuous piecewise-constant stochastic process $S(t)$ taking values in a state space $\cS$. % (see Figure~\ref{fig:naive_mh}, top-left).
We assume a finite number of states $N$, with $\cS = \{1,\ldots,N\}$. 
Then, the MJP is parameterized by two quantities, an $N$-component probability vector $\pi_0$ and a rate-matrix $A$. 
The former gives the distribution over states at the initial time (we assume this is $0$), while the latter is an $N \times N$-matrix governing the dynamics of the system.  
An off-diagonal element $A_{ij}$ gives the rate of transitioning from state $i$ to $j$. 
The rows of $A$ sum to $0$, so that $A_{ii}=-\sum_{j \neq i} A_{ij}  $. 
We write $A_i$ for the negative of the $i$th diagonal element $A_{ii}$, so that $A_i = -A_{ii}$ gives the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP over an interval $[0,t_{end})$, one follows Gillespie's algorithm~\citep{gillespie97}: 
first sample an initial state $s_0$ from $\pi_0$, and defining $t_0 = t_{curr} = 0$ and $k = 0$, repeat the following while $t_{curr} < t_{end}$:
\begin{itemize}
  \item Simulate a wait-time $\Delta t_k$ from an exponential distribution with rate $A_{s_k}$.  
    Set $t_{k+1} = t_{curr} = t_{k} + \Delta t_k$. 
    The MJP remains in state $s_k$ until time $t_{k+1}$.
  \item Jump to a new state $s_{k+1} \neq s_k$ with probability equal to $A_{s_ks_{k+1}}/A_{s_k}$. Set $k=k+1$.
\end{itemize}
The times $T=(t_1, \dotsc, t_{k - 1})$ and states $S=(s_1, \dotsc, s_{k - 1 })$, along with the initial state $s_0$, define the MJP path, so that $\{S(t), t \in [0,t_{end})\} \equiv (s_0, S,T)$. 
See the top-left panel in figure~\ref{fig:MH_improved} for a sample path.

\vspace{-.15in}
\subsection{Structured rate matrices}
While the rate matrix $A$ can have $N(N-1)$ independent elements, in typical applications, especially with large state-spaces, it is determined by a much smaller set of parameters. 
We will write these as $\theta$, with $A$ a deterministic function of these parameters: $A \equiv A(\theta)$. 
The parameters $\theta$ are often more interpretable than the elements of $A$, and correspond directly to physical, biological or environmental parameters of interest. 
For example:
\begin{description}
  \item[Immigration-death processes] 
    Here, $\theta = (\alpha,\beta)$, with $\alpha$ the arrival-rate and $\beta$ the death-rate. 
    The state represents the size of a population or queue. 
    New individuals enter with rate $\alpha$, so off-diagonal elements $A_{i,i+1}$ equal $\alpha$.
    Each individual dies at a rate $\beta$, so that $A_{i,i-1}=i\beta$ for each $i$.
    All other transitions have rate $0$. 
   % so that $\theta = (\alpha,\beta)$,
   % and $A(\theta)$ is tri-diagonal.
  \item[Birth-death processes] 
    This variant of the earlier MJP moves from state $i$ to $i+1$ with rate $i\alpha$, with growth-rate is proportional to population size. 
    The death-rate is $\beta$, so that $A_{i,i-1}=i\beta$ for each $i$.
    Other off-diagonal elements are $0$, and again $\theta=(\alpha,\beta)$.
  \item[Codon substitution models] 
    These characterize transitions between codons at a DNA locus over evolutionary time. 
    There are $61$ codons, and in the simplest case, all transitions have the same rate~\citep{jukescantor69}: $A_{ij} = \alpha\ \forall i \neq j$. 
    Thus the $61\times 61$ matrix $A$ is determined by a single $\alpha$. 
    Other models~\citep{goldman1994codon} group transitions as `synonymous' and `nonsynonymous', based on whether old and new codons encode the same amino acid. 
    Synonymous and nonsynonymous transitions have their own rates, so $A$ is now determined by 2 parameters $\alpha$ and $\beta$. 
  %  More refined models~\citep{goldman1994codon} introduce additional structure and parameters. 
    %however the 
    %number of parameters is still significantly smaller than the general case.
\end{description}
