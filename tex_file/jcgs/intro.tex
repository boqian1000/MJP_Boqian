
\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes 
widely used in fields like computational chemistry~\citep{gillespie97}, 
molecular genetics~\citep{FearnSher2006}, mathematical finance~\citep{Elliott06}, 
queuing theory~\citep{Breuer2003}, artificial intelligence~\citep{XuShe10} and
social-network analysis~\citep{pan2016markov}. %The references above have
These references have used MJPs to model temporal evolution of the state 
of a chemical reaction or queuing network, segmentation of a strand of 
DNA, user activity on social media, among many others, resulting in 
realistic, mechanistic, and interpretable models. %, often amenable to mathematical analysis. 
These same continuous-time dynamics however raise computational
challenges when, given noisy measurements, one wants to make inferences 
over the latent MJP trajectory as well as any parameters. 
In contrast to {discrete-time} hidden Markov models, one cannot 
{\em a priori} bound the number of state transitions, and the transition 
times themselves are continuous-valued. 
%and trajectory inference for 
%MJPs typically proceeds via Markov chain Monte Carlo. 
The state-of-the-art inference method for MJPs is an auxiliary variable 
Gibbs sampler from~\cite{RaoTeh13}, we will refer to this as the {\algname} 
algorithm. This  algorithm was designed to sample paths when the MJP parameters
are known. Parameter inference is typically carried out by 
incorporating it into a Gibbs sampler that also conditionally simulates
parameters given the currently sampled trajectory. 

In many situations, the MJP trajectory and parameters exhibit 
strong coupling, so that alternately samples path given
parameters, and parameters given path can result in poor mixing.  
To address this issue, we propose a simple, elegant and efficient 
Metropolis-Hastings framework. 
%additionally, we tie up some of the loose ends in the Rao-Teh algorithm.
In our experiments, we demonstrate superior 
performance over Gibbs sampling, as well as other approaches like 
particle Markov chain Monte Carlo~\citep{Andrieu10}. We also prove 
that under relatively mild conditions, our sampler inherits geometric 
ergodicity from an `ideal' sampler that operates without any computational 
constraints.

\section{Markov jump processes (MJPs)} 
A Markov jump process~\citep{Cinlar1975} is a right-continuous 
piecewise-constant stochastic process $S(t)$ taking values in a 
usually finite state space $\cS$. % (see Figure~\ref{fig:naive_mh}, top-left).
We assume $N$-states, with $\cS = \{1,\ldots,N\}$. Then, 
the MJP is parameterized by two quantities, an $N$-component probability vector 
$\pi_0$ and a rate-matrix $A$. The former gives the distribution over states at 
the initial time (we assume this is $0$), while 
the latter is an $N \times N$-matrix governing the dynamics of the system.  An 
off-diagonal element $A_{ij}$, for $i \neq j$ gives the rate 
of transitioning from state $i$ to $j$. 
The rows of $A$ sum to $0$, so that $A_{ii}=-\sum_{j \neq i} A_{ij}  $. 
We write $A_i$ for the negative of the $i$th diagonal element $A_{ii}$, 
so that $A_i = -A_{ii}$ gives the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP over an interval $[0,t_{end}]$, one follows 
Gillespie's algorithm~\citep{gillespie97}: 
first sample an initial state $s_0$ from $\pi_0$, and
defining $t_0 = t_{curr} = 0$ and $k = 0$, repeat the following while
$t_{curr} < t_{end}$:
\begin{itemize}
  \item Sample a wait-time $\Delta t_k$ from an exponential distribution with rate 
    $A_{s_k}$.  Set $t_{k+1} = t_{curr} = t_{k} + \Delta t_k$.
    The MJP remains in state $s_k$ until time $t_{k+1}$.
  \item Jump to a new state $s_{k+1} \neq s_k$ with 
    probability equal to $A_{s_ks_{k+1}}/A_{s_k}$. Set $k=k+1$.
\end{itemize}
The times $T=(t_0, \cdots, t_{|T| - 1})$ and states 
$S=(s_0, \cdots, s_{|T| - 1 })$ define the MJP path $S(t)$.

\subsection{Structured rate matrices}
While the rate matrix $A$ can have $N(N-1)$ independent elements,
%giving transition rates between every distinct pair of states. 
in typical applications, especially with large state-spaces, 
it is determined by a much smaller
set of parameters. We will write these as $\theta$, with
$A$ a deterministic function of these parameters: 
$A \equiv A(\theta)$. The parameters $\theta$ are often more 
interpretable than the elements of $A$ and correspond directly to
physical, biological or environmental parameters of interest. 
For example:
\begin{description}
  \item[Immigration-death processes] Here, $\theta = (\alpha,\beta)$
    with $\alpha$ the arrival-rate and $\beta$ the death-rate.
    The state represents the size of a 
    population or queue. New individuals
    enter with rate $\alpha$,
    so off-diagonal elements $A_{i,i+1}$ equal $\alpha$.
    Each individual dies %(or each job completes) 
    at a rate $\beta$, so that % system moves from $i$ to $i-1$ with rate 
    $A_{i,i-1}=i\beta$.
    All other transitions have rate $0$. 
   % so that $\theta = (\alpha,\beta)$,
   % and $A(\theta)$ is tri-diagonal.
  \item[Birth-death processes] This variant of the
    earlier MJP moves from state $i$ 
    to $i+1$ with rate $i\alpha$, with growth-rate proportional to 
    population size. Again, 
    $\theta=(\alpha,\beta)$.
  \item[Codon substitution models] These %are used in genetics
    characterize transitions between codons at a 
    DNA locus % on a DNA or RNA molecule 
    over evolutionary time. In the simplest case,
    all transitions have the same rate~\citep{jukescantor69}, 
    %requiring just a single parameter. 
    Other models group transitions 
    into, e.g., `synonymous' and `nonsynonymous' transitions, 
    that continue to or do not encode the same amino acid. 
   % and `nonsynonymous' transitions giving 
   % a new amino acid.  
    These have their own rates, and as 
    there are $61$ codons, this gives a 
    $61\times 61$ matrix determined by 2 parameters. More refined 
    models~\citep{goldman1994codon} introduce additional parameters. 
    %however the 
    %number of parameters is still significantly smaller than the general case.
\end{description}
