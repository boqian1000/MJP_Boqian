
\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes that
have found wide application in fields like computational chemistry~\cite{gillespie97}, 
population genetics~\cite{FearnSher2006}, mathematical finance~\cite{Elliott06}, 
queuing theory~\cite{Breuer2003}, artificial intelligence~\cite{XuShe10} and
social-network analysis~\cite{pan2016markov}. %The references above have
MJPs have been used to model the state of a chemical reaction, the state 
of a queuing network, segmentation of a strand of DNA, user activity on social 
media, among many others.

MJPs model temporal evolution in continuous-time, resulting in 
realistic, mechanistic, and interpretable models. %, often amenable to mathematical analysis. 
These same dynamics however raise computational
challenges in statistical applications, where given partial and noisy 
measurements, one has to make inferences over the latent MJP 
trajectory as well as any system parameters. Such
inference is complicated by two facts: one cannot {\em a priori} 
bound the number of state transitions, and the state-transition times themselves
are continuous-valued. This is in contrast to the situation with
{\em discrete-time} hidden Markov models. %and trajectory inference for 
%MJPs typically proceeds via Markov chain Monte Carlo. 
The state-of-the-art inference method for MJPs is an auxiliary variable Gibbs sampler proposed 
in~\cite{RaoTeh13}, we will henceforth refer to this as the {\algname} 
algorithm. The {\algname} algorithm was designed to sample paths when the MJP parameters
are known. Parameter inference is typically carried out by 
incorporating it into an outer Gibbs sampler that also simulates
parameters given the currently sampled trajectory. 

In many situations, the MJP trajectory and parameters can exhibit 
strong coupling, so that a Gibbs sampler that alternately samples path given
parameters, and then parameters given path can mix poorly.  
In this work, we propose a Metropolis-Hastings framework to address
this issue. Our proposed solution is simple and elegant, additionally,
it ties up some of the loose ends in the Rao-Teh algorithm.
In our experiments, we demonstrate superior 
performance over Gibbs sampling, as well as other approaches like 
particle Markov chain Monte Carlo~\cite{Andrieu10}.

\section{Markov jump processes (MJPs)} 
Formally, a Markov jump process~\cite{Cinlar1975} is a right-continuous 
piecewise-constant stochastic process $S(t)$ taking values in a countable, and 
usually finite state space $\cS$ (see Figure~\ref{fig:naive_mh}, top-left).
For simplicity, we will assume $N$-states, with $\cS = \{1,\ldots,N\}$. Then, 
an MJP is parameterized by two quantities, an $N$-component probability vector 
$\pi_0$ and a rate-matrix $A$. The former gives the distribution over states at 
the initial time (which without loss of generality we assume is $0$), while 
the latter is an $N \times N$-matrix governing the dynamics of the system.  An 
off-diagonal element $A_{ij}$, for some $i \neq j$ gives the rate at 
which the system transitions from state $i$ to $j$. We write $A_i$ for the 
negative of the $i$th diagonal element $A_{ii}$. For an MJP,
$A_i = -A_{ii} = \sum_{j \neq i} A_{ij}$, so that the rows of $A$ sum to $0$.  
$A_i$ gives the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP trajectory over an interval $[0,\cT]$, one follows 
Gillespie's algorithm~\cite{gillespie97}: 
first sample an initial state $s_0$ from the distribution $\pi$, and
then defining $t_0 = t_{curr} = 0$ and $k = 0$, repeat the following two steps while
$t_{curr} < \cT$:
\begin{itemize}
  \item Sample a wait-time $\Delta t_k$ from an exponential distribution with rate 
    $A_{s_k}$.  Set $t_{k+1} = t_{curr} = t_{k} + \Delta t_k$.
    The MJP remains in state $s_k$ until time $t_{k+1}$.
  \item At the end of this time, jump to a new state $s_{k+1} \neq s_k$ with 
    probability equal to $A_{s_ks_{k+1}}/A_{s_k}$. Set $k=k+1$.
\end{itemize}
The times $T=(t_0, \cdots, t_{|T| })$ and states 
$S=(s_0, \cdots, s_{|T| })$ define the MJP path $S(t)$.

\subsection{Structured rate matrices}
In general, the rate matrix $A$ has $N(N-1)$ free parameters,
giving transition rates between every distinct pair of states. 
In typical applications, especially when large state-spaces
are involved, this $N \times N$ matrix is determined by a much smaller
set of parameters. We will write these as $\theta$, with
$A$ a deterministic function of these parameters: 
$A \equiv A(\theta)$. The parameters $\theta$ are often more 
interpretable than the elements of $A$ and correspond directly to
physical, biological or environmental parameters of interest. 
For example:
\begin{description}
  \item[The immigration-death process] This MJP is governed
    by two parameters: an arrival rate $\alpha$ and a death-rate
    $\beta$. The state space $\cS$ represents the size of a 
    population or the capacity of a queue. New individuals
    enter according to a rate-$\alpha$ Poisson process,
    so off-diagonal elements $A_{i,i+1}$ all equal $\alpha$.
    Each individual dies %(or each job completes) 
    at a rate $\beta$, so the system moves from state $i$ to 
    $i-1$ with rate $A_{i,i-1}=i\beta$.
    All other transitions have rate $0$, so that $\theta = (\alpha,\beta)$,
    and $A(\theta)$ is a tri-diagonal matrix.
  \item[Birth-death processes] This variant of the
    earlier MJP moves from state $i$ 
    to $i+1$ with rate $i\alpha$, with growth-rate proportional to 
    population size. Again, 
    $\theta=(\alpha,\beta)$.
  \item[Codon substitution models] Such models %are used in genetics
    characterize transition-rates between nucleotides or codons at a 
    DNA or RNA locus % on a DNA or RNA molecule 
    over evolutionary time. In the simplest case,
    all transitions have the same rate~\cite{jukescantor69}, 
    requiring just a single parameter. Other models categorize transitions 
    into groups, for instance `synonymous' transitions that continue to 
    encode the same amino acid, and `nonsynonymous' transitions giving 
    a new amino acid.  These have their own rates, and as 
    there are $61$ codons, this model results in a 
    $61\times 61$ transition matrix determined by 2 parameters. More refined 
    models~\cite{goldman1994codon} can introduce additional parameters. 
    %however the 
    %number of parameters is still significantly smaller than the general case.
\end{description}
