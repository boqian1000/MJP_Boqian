\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes that
have found wide application in fields like computational chemistry~\cite{gillespie97}, 
population genetics~\cite{FearnSher2006}, mathematical finance~\cite{Elliott06}, 
queuing theory~\cite{Breuer2003}, artificial intelligence~\cite{XuShe10} and
social-network analysis~\cite{pan2016markov}. The references included above have
used MJPs to model phenomena such as the state of a chemical reaction, the state 
of a queuing network, segmentations of a strand of DNA, the state of users 
logging their activity on social media, among others.

MJPs model temporal evolution in continuous-time, resulting in 
realistic, mechanistic, and interpretable models, often amenable to 
mathematical analysis. These same dynamics however raise computational
challenges in statistical applications, where given partal and noisy 
measurements, one has to make inferences over the latent MJP 
trajectory as well as any system parameters. Carrying out such
inference is complicated by two facts: one cannot {\em a priori} 
bound the number of state transitions, and state-transition times themselves
are continuous-valued. This is in contrast to the situation with
discrete-time hidden Markov models, and trajectory inference for 
MJPs typically proceeds via Markov chain Monte Carlo. The 
state-of-the-art is a recent auxiliary variable Gibbs sampler proposed 
in~\cite{RaoTeh13},  designed to sample paths when the MJP parameters
are known. Parameter inference is typically carried out by 
incorporating it into a larger Gibbs sampler. 

In many situations, the MJP trajectory and parameters can exhibit 
strong coupling, so that a Gibbs that alternately samples path given
parameters, and then parameters given path can mix poorly.  
In this work, we propose a Metropolis-Hastings framework to address
this issue. Our proposed solution is simple and elegant, additionally,
it ties up some of the loose ends in the algorithm 
from~\cite{RaoTeh13}.  In our experiments, we demonstrate superior 
performance over Gibbs sampling, as well as other approaches like 
particle Markov chain Monte Carlo~\cite{Andrieu10}.

\section{Markov jump processes}
Formally, an MJP is a right-continuous piecewise-constant stochastic
process $S(t)$ taking values in a countable, and usually finite state
space $\cS$ (see Figure~\ref{fig:naive_mh}, top-left).
\vinayak{Change figures so that transitions are not so regular}
For simplicity, we will assume $N$-states, with $\cS = \{1,\ldots,N\}$. Then, 
an MJP is parameterized by two quantities, a probability vector $\pi$ and a 
rate-matrix $A$. The former, an $N$-component vector, gives the 
distribution over states at the initial time (which without loss of 
generality, we assume is $0$), while the latter is an 
$N \times N$-matrix governing the dynamics of the system.  An 
off-diagonal element $A_{ij}$, for some $i \neq j$ gives the rate at 
which the system transitions from state $i$ to $j$. We write the 
$i$th diagonal element as $-A_{ii}$ (or $-A_i$ for short), with
$A_i \equiv A_{ii} = \sum_{j \neq i} A_{ij}$, 
so that the rows of $A$ sum to $0$.  $A_i$ is the absolute value of the diagonal,
and gives the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP trajectory over an interval $[0,\cT]$, one follows 
Gillespie's algorithm~\cite{gillespie97}: 
first sample an initial state $s_0$ from the distribution $\pi$, and
then defining $t_0 = t_{curr} = k = 0$, repeat the following two steps while
$t_{curr} < \cT$:
\begin{itemize}
  \item Sample a wait-time $\Delta t_k$ from an exponential with rate $A_{s_k}$. 
    Set $t_{k+1} = t_{curr} = t_{k} + \Delta t_k$.
    The MJP remains in state $s_k$ until time $t_{k+1}$.
  \item At the end of this time, jump to a new state $s_{k+1} \neq s_k$ with 
    probability equal to $A_{s_ks_{k+1}}/A_{s_k}$. Set $k=k+1$.
\end{itemize}
The set of times of $T=(t_0, \cdots, t_{|T| - 1})$ and states 
$S=(s_0, \cdots, s_{|T| - })$ together define the MJP trajectory $S(t)$.

\subsection{Structured rate matrices}
In the general case, the rate matrix $A$ has $N(N-1)$ free parameters,
corresponding to transition rates between every pair of distinct states. 
In typical applications, and especially when large state-spaces
are involved, this $N \times N$ matrix is determined by a much smaller
set of parameters. We will write these as $\theta$, and the rate 
matrix $A$ is a deterministic function of these parameters: 
$A \equiv A(\theta)$. The parameters $\theta$ are often much more 
interpretable than the elements of $A$, corresponding directly to
physical, biological or environmental parameters of interest. 
Below we give three examples:
\begin{description}
  \item[The immigration-death process] This is a simple MJP governed
    by two parameters: an arrival rate $\alpha$ and a death-rate
    $\beta$. The state space $\cS$ represents the size of a 
    population or the capacity of a queue. New individuals
    enter the system according to a rate-$\alpha$ Poisson process,
    so that the off-diagonal elements $A_{i,i+1}$ all equal to $\alpha$.
    On the other hand, each individual dies (or each job completes) 
    at a rate $\beta$, so that the system moves from state $i$ to 
    $i-1$ with rate $A_{i,i-1}=i\beta$.
    All other transitions have rate $0$, so that $\theta = (\alpha,\beta)$,
    and $A(\theta)$ is a tri-diagonal matrix.
  \item[Birth-death processes] This is a simple variant of the
    immigration-death process where the system moves from state $i$ 
    to $i+1$ with rate $i\alpha$, so that the population grows at a 
    rate proportional to the population size. Once again, 
    $\theta=(\alpha,\beta)$.
  \item[Codon substitution models] Such models are used in genetics,
    to characterize transition-rates between codons at a locus on
    a DNA or RNA molecule over evolutionary time. In the simplest case,
    transitions are categorized into two types: synonymous transitions
    that encode the same amino acid, and nonsynonymous 
    transitions that encode different amino acids. 
    These two transitions types have their own rates, and noting that 
    there are $61$ amino acids, we have a $61\times 61$ transition
    matrix determined by 2 parameters. More refined models~\cite[e.g.][]{goldman1994codon} introduce
    additional parameters, however, the number of parameters is still
    significantly smaller than the general case.
\end{description}
