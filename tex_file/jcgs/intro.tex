\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes that
have found wide application in fields like computational chemistry, 
population genetics, mathematical finance, artificial intelligence and
social-network analysis. MJPs have been used to model phenomena such 
as the state of a chemical reaction~\cite{a}, the state of a queuing 
network~\cite{a}, segmentations of a strand of DNA~\cite{a}, the state of 
users logging their activity on social media~\cite{a} among many others
Their temporal evolution in continuous-time nature results
in realistic, mechanistic, and interpretable models, often amenable to 
mathematical analysis.  These same dynamics however raise computational
challenges in statistical applications, where given partal and noisy 
measurements,
one has to make inferences over  the latent MJP trajectory as well
as any system parameters. Carrying out inferences over the 
latent MJP trajectory, and any system parameters, is complicated by two
facts: one cannot {\em a priori} bound the number of transitions, and 
state-transition times are continuous-valued. Inference for these models 
typically proceeds via Markov chain Monte Carlo, the state-of-the-art 
being a recent auxiliary variable Gibbs sampler proposed 
in~\cite{RaoTeh13}.  This algorithm was designed to sample MJP paths 
when the MJP parameters 
are known, and parameter inference is typically carried out by 
incorporating it into a larger Gibbs sampler. 

In many situations, the MJP trajectory and parameters can exhibit strong 
coupling, so that the Gibbs described earlier can mix poorly.  
In this work, we propose a Metropolis-Hastings framework to address
this issue. Our proposed solution is simple, elegant and ties
up some of the loose ends in the algorithm from~\cite{RaoTeh13}.
In our experiments, we demonstrate superior performance over Gibbs
sampling, as well as other approaches like particle Markov chain Monte 
Carlo~\cite{Andrieu10}.

\section{Markov jump processes}
Formally, an MJP is a right-continuous piecewise-constant stochastic
process $S(t)$ taking values in a countable, and usually finite state
space $\cS$ (see Figure~\ref{fig:mjp}). For simplicity, we will assume 
$N$-states, with $\cS = \{1,\ldots,n\}$. Then, an MJP is 
parameterized by two quantities, a probability vector $\pi$ and a 
rate-matrix $A$. The former, an $n$-component vector, gives the 
distribution over states at the 
initial time (which without loss of generality, we assume is 0), while 
the latter is an $n \times n$-matrix governing the dynamics of the system.
An off-diagonal element $A_{ij}$, for some $i \neq j$ gives the rate at 
which the system transitions from state $i$ to $j$. The rows of $A$ sum
to $0$, so that the diagonal element $A_i \equiv A_{ii} = -\sum_{j \neq i} A_{ij}$, 
and its absolute value gives
the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP trajectory, one first samples an initial state $S(0)$ 
from the distribution $\pi$, after which we repeat the following two steps:
\begin{itemize}
  \item Sample a wait-time $t_i$ from an exponential with rate $A_i$, where
    $i$ is the current state. The MJP remains in state $i$ for time $t_i$.
  \item At the end of this time, jump to a new state $j \neq i$ with 
    probability proportional to $A_{ij}$.
\end{itemize}

\subsection{Structured rate matrices}
In the general case, the rate matrix $A$ has $n(n-1)$ free parameters,
corresponding to transition rates between every pair of distinct states. 
In typical applications, and especially when large state-spaces
are involved, this $n \times n$ matrix is determined by a much smaller
set of parameters. We will write these as $\theta$, and the rate 
matrix $A$ is a deterministic function of these parameters: 
$A \equiv A(\theta)$. The parameters $\theta$ are often much more 
interpretable than the elements of $A$, corresponding directly to
physical, biological or environmental parameters of interest. 
Below we give three examples:
\begin{description}
  \item[The immigration-death process] This is a simple MJP governed
    by two parameters: an arrival rate $\alpha$ and a `death'-rate
    $\beta$. The state space $\cS$ represents the size of a 
    population or the number of jobs in a queue, and can be finite or
    countably infinite. New individuals
    enter the system according to a rate-$\alpha$ Poisson process,
    so that the off-diagonal elements $A_{i,i+}$ all equal to $\alpha$.
    On the other hand, each individual dies at a rate $\beta$, so
    that the system moves from state $i$ to $i-1$ with rate $i\beta$.
    All other transitions have rate $0$, so that $\theta = (\alpha,\beta)$,
    and $(\theta)$ is a tri-diagonal matrix.
  \item[Birth-death processes] This is a simple variant of the
    immigration where the system moves from state $i$ to $i+1$ with
    rate $i\alpha$, so that the population grows at a rate proportional
    to the population size. Once again, $\theta=(\alpha,\beta)$.
  \item[Jules-Cantor model] This is popular model in genetics used to 
    characterize the transition rates between amino-acids at a locus
    over evolutionary time. In this model, transitions are categorized
    into two types: synonymous transitions that encode
\end{description}

\subsection{Bayesian inference for MJPs}
In realistic situations, one only observes the MJP trajectory at
a finite set of times, and typically, these observations themselves
are unknown. There are then two challenges than the practitioner
faces:
\begin{itemize}
  \item What is the MJP trajectory underlying the observations?
  \item What are the unknown parameters governing the MJP dynamics?
\end{itemize}
