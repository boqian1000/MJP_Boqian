\section{Introduction}
\label{sec:intro}
Markov jump processes (MJPs) are continuous-time stochastic processes that
have found wide application in fields like computational chemistry~\cite{gillespie97}, 
population genetics~\cite{FearnSher2006}, mathematical finance~\cite{Elliott06}, 
queuing theory~\cite{Breuer2003}, artificial intelligence~\cite{XuShe10} and
social-network analysis~\cite{pan2016markov}. %The references above have
MJPs have been used to model phenomena such as the state of a chemical reaction, the state 
of a queuing network, segmentations of a strand of DNA, the state of users 
logging their activity on social media, among many others.

MJPs model temporal evolution in continuous-time, resulting in 
realistic, mechanistic, and interpretable models, often amenable to 
mathematical analysis. These same dynamics however raise computational
challenges in statistical applications, where given partial and noisy 
measurements, one has to make inferences over the latent MJP 
trajectory as well as any system parameters. Such
inference is complicated by two facts: one cannot {\em a priori} 
bound the number of state transitions, and the state-transition times themselves
are continuous-valued. This is in contrast to the situation with
{\em discrete-time} hidden Markov models, and trajectory inference for 
MJPs typically proceeds via Markov chain Monte Carlo. The 
state-of-the-art is a recent auxiliary variable Gibbs sampler proposed 
in~\cite{RaoTeh13}, we will henceforth refer to this as the Rao-Teh algorithm.
The Rao-Teh algorithm was designed to sample paths when the MJP parameters
are known. Parameter inference is typically carried out by 
incorporating this into an outer Gibbs sampler that simulates
parameters given the currently sampled trajectory. 

In many situations, the MJP trajectory and parameters can exhibit 
strong coupling, so that a Gibbs sampler that alternately samples path given
parameters, and then parameters given path can mix poorly.  
In this work, we propose a Metropolis-Hastings framework to address
this issue. Our proposed solution is simple and elegant, additionally,
it ties up some of the loose ends in the Rao-Teh algorithm.
In our experiments, we demonstrate superior 
performance over Gibbs sampling, as well as other approaches like 
particle Markov chain Monte Carlo~\cite{Andrieu10}.

\section{Markov jump processes}
Formally, an MJP is a right-continuous piecewise-constant stochastic
process $S(t)$ taking values in a countable, and usually finite state
space $\cS$ (see Figure~\ref{fig:naive_mh}, top-left).
For simplicity, we will assume $N$-states, with $\cS = \{1,\ldots,N\}$. Then, 
an MJP is parameterized by two quantities, a probability vector $\pi$ and a 
rate-matrix $A$. The former, an $N$-component vector, gives the 
distribution over states at the initial time (which without loss of 
generality, we assume is $0$), while the latter is an 
$N \times N$-matrix governing the dynamics of the system.  An 
off-diagonal element $A_{ij}$, for some $i \neq j$ gives the rate at 
which the system transitions from state $i$ to $j$. We write $A_i$ for the 
negative of the $i$th diagonal element $A_{ii}$. For an MJP,
$A_i = -A_{ii} = \sum_{j \neq i} A_{ij}$, so that the rows of $A$ sum to $0$.  
$A_i$ is the absolute value of the diagonal,
and gives the total rate at which the system leaves state $i$ for any other state.
To simulate an MJP trajectory over an interval $[0,\cT]$, one follows 
Gillespie's algorithm~\cite{gillespie97}: 
first sample an initial state $s_0$ from the distribution $\pi$, and
then defining $t_0 = t_{curr} = 0$ and $k = 0$, repeat the following two steps while
$t_{curr} < \cT$:
\begin{itemize}
  \item Sample a wait-time $\Delta t_k$ from an exponential distribution with rate 
    $A_{s_k}$.  Set $t_{k+1} = t_{curr} = t_{k} + \Delta t_k$.
    The MJP remains in state $s_k$ until time $t_{k+1}$.
  \item At the end of this time, jump to a new state $s_{k+1} \neq s_k$ with 
    probability equal to $A_{s_ks_{k+1}}/A_{s_k}$. Set $k=k+1$.
\end{itemize}
The set of times of $T=(t_0, \cdots, t_{|T| })$ and states 
$S=(s_0, \cdots, s_{|T| })$ together define the MJP trajectory $S(t)$.

\subsection{Structured rate matrices}
In the general case, the rate matrix $A$ has $N(N-1)$ free parameters,
corresponding to transition rates between every distinct pair of states. 
In typical applications, especially when large state-spaces
are involved, this $N \times N$ matrix is determined by a much smaller
set of parameters. We will write these as $\theta$, so that 
$A$ is a deterministic function of these parameters: 
$A \equiv A(\theta)$. The parameters $\theta$ are often more 
interpretable than the elements of $A$, corresponding directly to
physical, biological or environmental parameters of interest. 
We give three examples below:
\begin{description}
  \item[The immigration-death process] This is a simple MJP governed
    by two parameters: an arrival rate $\alpha$ and a death-rate
    $\beta$. The state space $\cS$ represents the size of a 
    population or the capacity of a queue. New individuals
    enter the system according to a rate-$\alpha$ Poisson process,
    so that the off-diagonal elements $A_{i,i+1}$ all equal to $\alpha$.
    On the other hand, each individual dies (or each job completes) 
    at a rate $\beta$, so that the system moves from state $i$ to 
    $i-1$ with rate $A_{i,i-1}=i\beta$.
    All other transitions have rate $0$, so that $\theta = (\alpha,\beta)$,
    and $A(\theta)$ is a tri-diagonal matrix.
  \item[Birth-death processes] This is a simple variant of the
    immigration-death process where the system moves from state $i$ 
    to $i+1$ with rate $i\alpha$, so that the population grows at a 
    rate proportional to the population size. Once again, 
    $\theta=(\alpha,\beta)$.
  \item[Codon substitution models] Such models are used in genetics,
    to characterize transition-rates between nucleotides or codons at a locus on
    a DNA or RNA molecule over evolutionary time. In the simplest case,
    all transitions have the same rate~\cite{jukescantor69}, and the model is 
    characterized by a single parameter. In other models, transitions might be 
    categorized into groups, for instance, synonymous transitions that encode 
    the same amino acid, and nonsynonymous transitions that encode different 
    amino acids.  These transitions types have their own rates, and noting that 
    there are $61$ amino acids, synonymous/nonsynonymous model results in a 
    $61\times 61$ transition matrix determined by 2 parameters. More refined 
    models~\cite{goldman1994codon} introduce additional parameters, however the 
    number of parameters is still significantly smaller than the general case.
\end{description}
