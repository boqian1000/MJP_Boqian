\documentclass[12pt]{article}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{amssymb,mathabx}
\usepackage{algorithm, algpseudocode}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newcommand{\blind}{0}
\addtolength{\oddsidemargin}{-.75in}%
\addtolength{\evensidemargin}{-.75in}%
\addtolength{\textwidth}{1.5in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\input{mymacros.tex}

\begin{document}


%\bibliographystyle{plain}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Efficient MCMC for parameter inference for Markov jump processes}
  \author{  
   %  Vinayak Rao\thanks{
    %The authors gratefully acknowledge}\hspace{.2cm}\\
    %Department of Statistics, Purdue University\\
    %and \\
    Boqian Zhang \\
    Department of Statistics, Purdue University\\
    Vinayak Rao\\
    Department of Statistics, Purdue University\\
    }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title}
\end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Markov jump processes (MJPs) are continuous-time stochastic processes that 
find wide application in a variety of disciplines. Inference for MJPs typically 
proceeds via Markov chain Monte Carlo, the state-of-the-art being an auxiliary 
variable Gibbs sampler proposed recently in~\cite{RaoTeh13}. This algorithm was 
designed for the situation where the MJP parameters are known, and Bayesian 
inference over unknown parameters is typically carried out by incorporating 
this into a larger Gibbs sampler. 
%In many situations, the MJP trajectory and parameters can exhibit
%strong coupling, and 
This strategy of alternately sampling parameters given path, and 
then path given parameters can result in poor Markov chain mixing. In this 
work, we propose a simple and elegant algorithm to address this 
problem. Our scheme brings Metropolis-Hastings (MH) approaches 
for discrete-time hidden Markov models (HMMs) to the continuous-time
setting, and also also ties up some of the loose ends 
in~\cite{RaoTeh13}. The result is a complete and clean recipe for 
parameter and path inference in MJPs. In our experiments, we 
demonstrate superior performance over the Gibbs sampling approach, as well as 
other approaches like particle Markov chain Monte Carlo~\cite{Andrieu10}.
\end{abstract}
\noindent%
{\it Keywords:}  Markov jump process, Markov chain Monte Carlo, Metropolis-Hasting, Bayesian 
inference, Uniformization 
\spacingset{1.45}
\input{intro.tex}
\input{unif.tex}
\input{simple_mh.tex}
\input{main_alg.tex}
\input{verif_alg2.tex}


\input{expt.tex}



\bigskip
%\begin{center}
%{\large\bf SUPPLEMENTAL MATERIALS}
%\end{center}

%\begin{description}

%\item[Title:] Brief description. (file type)

%\item[R-package for  MYNEW routine:] R-package ÒMYNEWÓ containing code to perform the diagnostic methods described in the article. The package also contains all datasets used as examples in the article. (GNU zipped tar file)

%\item[HIV data set:] Data set used in the illustration of MYNEW method in Section~ 3.2. (.txt file)

%\end{description}

% ~\nocite{RaoTeh13}
% ~\nocite{RaoTeh12}
% ~\nocite{Andrieu10}
% ~\nocite{Andrieu09}
% ~\nocite{Golightly15}
% ~\nocite{Andrieu102}
% ~\nocite{Liu94}
% ~\nocite{Neal12}
% ~\nocite{Neal03}
% ~\nocite{geoergo}
\bibliography{bibfile}
\bibliographystyle{plain}
\pagebreak
\input{supp.tex}
%\input{proof.tex}
\end{document}
