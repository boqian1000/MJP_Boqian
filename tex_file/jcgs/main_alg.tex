
\section{An improved Metropolis-Hasting algorithm}
Our main idea is to symmetrize the probability of $W$ under the old and new 
$\theta$, so that the term
$p(W|\theta)$ disappears from the acceptance ratio. This will result
in a significantly more efficient, and also a simpler MCMC scheme.
%This forms the main contribution of this paper.
As before, the MCMC iteration begins with the pair $(S(t), \theta)$. 
Instead of simulating the Poisson events $U$, we first generate a new 
parameter $\vartheta$ from $q(\vartheta|\theta)$. Treat this as an 
auxiliary variable, so that the augmented space now is the triplet 
$(S(t), \theta,\vartheta)$. We pretend $S(t)$ was sampled by a 
uniformization scheme where the dominating Poisson rate $\Omega$ equals 
$(\Omega(\theta) + \Omega(\vartheta))$ instead of just $\Omega(\theta)$ 
(recall any choice greater than $\max_i A_i$ is valid).
Now follows the set of thinned events $U$ is piecewise-constant
Poisson with intensity $\Omega(\theta) + \Omega(\vartheta) - 
A_{S(t)}$. Following~\cite{RaoTeh13}, the set $W$, the union of these events 
with the actual
trajectory transition times $T$, is a homogeneous Poisson process with 
rate $\Omega(\theta) + \Omega(\vartheta)$. Now discard all MJP 
state information, so that the MCMC state space is $(W, \theta, \vartheta)$.
Now make an MH proposal that swaps $\theta$ with $\vartheta$. 
Observe from
symmetry that the Poisson skeleton $W$ has the same probability both
before and after this proposal, so that unlike the previous scheme,
the ratio $p(W|\vartheta)/p(W|\theta)$ equals $1$.  This simplifies 
computation, and significantly improves mixing.
The acceptance probability 
%depends only on the probability of the observations
%under both set of parameters, %as we can use the forward-backward algorithm
%to calculate this. Our acceptance probability 
equals
$ \text{acc} = 
  \min\left(1, \frac{p(X,\vartheta)q(\theta|\vartheta)}
   {p(X,\theta)q(\vartheta|\theta)}\right) = 
  \min\left(1, \frac{p(X|\vartheta)p(\vartheta)q(\theta|\vartheta)}
   {p(X|\theta)p(\theta)q(\vartheta|\theta)}\right).
   $
   The terms $p(X|\vartheta)$ and  $p(X|\theta)$ can be calculated by 
   running a forward pass of the forward-backward algorithm, and after
   accepting or rejecting the proposal, a new trajectory is sampled by
   completing the backward pass. Finally, the thinned events are
   discarded. We sketch out our algorithm in 
   figure~\ref{fig:MH_improved} and algorithm~\ref{alg:MH_improved}.
\begin{algorithm}[H]
   \caption{Improved MH for parameter inference for MJPs }
   \label{alg:MH_improved}
  \begin{tabular}{l l}
   \textbf{Input:  } & \text{The observations $X$,}
                      \text{the previous MJP path $S(t) = (S, T)$ and parameters $\theta$ \boqian{and $\pi_0$}}.\\ 
                     & \text{A  Metropolis-Hasting proposal $q(\cdot | \theta)$}.\\
   \textbf{Output:  }& \text{A new MJP trajectory $S'(t) = (S', T')$, 
                            new MJP parameters $\theta'$}.\\
   \hline
   \end{tabular}
   \begin{algorithmic}[1]
      \State Sample $\vartheta \sim q(\cdot| \theta)$, and 
      set %$\Omega = \max_i A_i(\theta) + \max_i A_i(\theta^*)$. 
	$\Omega \boqian{\equiv} = \Omega(\theta) + \Omega(\vartheta)$.
      %In the case of uniformization, we
      %have a single $\Omega$ for all states, with $\Omega = \max_i A_i(\theta) + \max_i A_i(\theta^*)$.
      %, with $h(\theta) > max_s{|A_s(\theta)|}$, $h(\theta^*) > max_s{|A_s(\theta^*)|}$ using some deterministic function $h$.
    \State Sample virtual jumps $U\subset[t_{start}, t_{end}]$ from a Poisson process with 
    piecewise-constant rate $R(t) = (\Omega - A_{S(t)}(\theta))$. 
    Set $W = T \cup U$ and discard MJP states.
    \State The current MCMC state-space is $(W,\theta,\vartheta)$. Propose swapping
    $\theta$ and $\vartheta$/ %the new state-space is 
   %\boqian{ $(W, \vartheta, \theta)$.}
%$(W, \theta, \vartheta)$    
     The acceptance probability is given by
   % accept $\theta^*$ as $\tilde{\theta}$ with probability $\alpha$.
        \begin{align*}
        \alpha %&=  1 \wedge \frac{P(W,(\vartheta, \theta)| y)}{P(W, (\theta, \vartheta)| y)}\\
       % &=  1 \wedge \frac{P(y| W,\vartheta, \theta) P(W | (\vartheta, \theta))p((\vartheta, \theta))}{P(y| W,(\theta, \vartheta)) P(W | (\theta, \vartheta))p((\theta, \vartheta))}\\
        &=  1 \wedge \frac{p(X| W,\vartheta,\theta)p(\vartheta)q(\theta|\vartheta)}
        {p(X| W,\theta, \vartheta)p(\theta) q(\vartheta|\theta)}.
        \end{align*}
    \State For both $\theta$ and $\vartheta$, make a forward pass through the 
    elements of $W$, sequentially updating the distribution over states at 
    $w \in W$ given observations upto $w$. At the end, we have calculated
    $p(X|W,\theta)$ and $p(X|W,\vartheta)$. Use these to accept or reject the
    proposed swapping of $\theta$ and $\vartheta$. Write the new state-space
    as $(W,\theta',\vartheta')$.
    \State For the new parameter $\theta'$, make a backward pass through 
    the elements of
    $W$, sequentially assigning a state to each element of $W$.
%    Sample a path $\tilde{V}$, from a discret-time Markov chain with $|W| + 1$ steps, using FFBS algorithm. The transition matrix of the Markov chain is $B = (I + \frac{A(\tilde{\theta})}{\Omega})$ while the initial distribution over states is $\pi_0$. The likelihood of state $s$ at step $i$ is 
%    $$ L_i(s) = P(Y_{[w_i, w_{i + 1})} | S(t) = s \; for\; t \in [w_i, w_{i + 1})) = \prod_{j: t_j \in [w_i, w_{i + 1})}p(y_{t_j} | S(t_j) = s).$$\\
%%(i.e. $V(i) \sim P(V |  \theta(i), W(i - 1), y).$) Then delete all the virtual jumps to get $S(i), T(i) .$\\
    \State Let $T'$ be the set of times in $W$ when the Markov chain changes state. Define $S'$ as the corresponding set of state values. Return $(S', T', \theta')$.
\end{algorithmic}
\end{algorithm}

